{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Machine Learning Model for House Price Prediction\n",
    "\n",
    "This notebook implements:\n",
    "- **Task 2a**: Robust ML algorithm for price prediction\n",
    "- **Task 2b**: Feature relationship analysis and importance\n",
    "\n",
    "## Table of Contents\n",
    "1. Data Loading and Preprocessing\n",
    "2. Feature Engineering\n",
    "3. Model Training and Evaluation\n",
    "4. Feature Importance Analysis\n",
    "5. Feature Relationships with Price\n",
    "6. Model Comparison and Selection\n",
    "7. Final Model and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from feature_engineering import FeatureEngineer\n",
    "from model_training import HousePricePredictor\n",
    "from model_evaluation import *\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Preprocess the data\n",
    "X, y = preprocessor.preprocess(df, target_col='SalePrice', \n",
    "                                scale=False, handle_outliers_flag=True)\n",
    "\n",
    "print(f\"\\nProcessed data shapes:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Create new features\n",
    "X_engineered = feature_engineer.create_all_features(X)\n",
    "\n",
    "print(f\"\\nShape after feature engineering: {X_engineered.shape}\")\n",
    "print(f\"Added {X_engineered.shape[1] - X.shape[1]} new features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Select top features\n",
    "# Uncomment the following lines to use feature selection\n",
    "# X_selected = feature_engineer.select_features(X_engineered, y, k=50)\n",
    "# X_final = X_selected\n",
    "\n",
    "# Using all engineered features\n",
    "X_final = X_engineered\n",
    "print(f\"Final feature count: {X_final.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = HousePricePredictor()\n",
    "\n",
    "# Train all models and compare\n",
    "results_df = predictor.train_all_models(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plot_model_comparison(results_df, metric='RMSE', \n",
    "                     title='Model Performance Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on best model\n",
    "best_model = predictor.best_model\n",
    "cv_results = predictor.cross_validate(best_model, X_train, y_train, cv=5)\n",
    "\n",
    "print(f\"\\nCross-Validation Results for {predictor.best_model_name}:\")\n",
    "print(f\"Mean RMSE: ${cv_results['mean_score']:,.2f}\")\n",
    "print(f\"Std RMSE: ${cv_results['std_score']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis (Task 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model (if tree-based)\n",
    "if hasattr(predictor.best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X_final.columns,\n",
    "        'Importance': predictor.best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 20 Most Important Features:\")\n",
    "    print(importance_df.head(20))\n",
    "    \n",
    "    # Visualize\n",
    "    plot_feature_importance(importance_df, \n",
    "                           title=f'Feature Importance - {predictor.best_model_name}',\n",
    "                           top_n=20)\n",
    "else:\n",
    "    print(f\"{predictor.best_model_name} does not provide feature importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Relationships with Price (Task 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for top features\n",
    "if hasattr(predictor.best_model, 'feature_importances_'):\n",
    "    top_features = importance_df.head(10)['Feature'].tolist()\n",
    "    \n",
    "    # Add target to correlation analysis\n",
    "    corr_data = X_train[top_features].copy()\n",
    "    corr_data['SalePrice'] = y_train.values\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = corr_data.corr()['SalePrice'].sort_values(ascending=False)\n",
    "    print(\"Correlation of Top Features with Sale Price:\")\n",
    "    print(correlations)\n",
    "    \n",
    "    # Visualize correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_data.corr(), annot=True, fmt='.2f', cmap='coolwarm',\n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix - Top 10 Important Features + SalePrice')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots showing relationships\n",
    "if hasattr(predictor.best_model, 'feature_importances_'):\n",
    "    top_4_features = importance_df.head(4)['Feature'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feat in enumerate(top_4_features):\n",
    "        axes[i].scatter(X_train[feat], y_train, alpha=0.5, \n",
    "                       edgecolors='k', linewidth=0.5)\n",
    "        axes[i].set_xlabel(feat)\n",
    "        axes[i].set_ylabel('Sale Price ($)')\n",
    "        axes[i].set_title(f'{feat} vs Sale Price')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trendline\n",
    "        z = np.polyfit(X_train[feat], y_train, 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[i].plot(X_train[feat], p(X_train[feat]), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation - Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "y_pred = predictor.best_model.predict(X_val)\n",
    "\n",
    "# Create comprehensive evaluation report\n",
    "metrics = create_evaluation_report(y_val, y_pred, \n",
    "                                  model_name=predictor.best_model_name,\n",
    "                                  save_dir='../outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "predictor.save_model(model_name=predictor.best_model_name, \n",
    "                    filepath='../models/best_model.pkl')\n",
    "\n",
    "# Also save the preprocessor and feature engineer for later use\n",
    "import joblib\n",
    "joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "joblib.dump(feature_engineer, '../models/feature_engineer.pkl')\n",
    "\n",
    "print(\"Models and processors saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings - Task 2\n",
    "\n",
    "### Task 2a: Machine Learning Algorithm\n",
    "- **Best Model**: The best performing model and its metrics are shown above\n",
    "- **Performance**: Evaluated using RMSE, MAE, and RÂ² metrics\n",
    "- **Robustness**: Cross-validation ensures model generalization\n",
    "\n",
    "### Task 2b: Feature Relationships and Price Variation\n",
    "- **Feature Importance**: Top features identified through model analysis\n",
    "- **Correlations**: Strong correlations visualized and quantified\n",
    "- **Price Variation**: Price varies based on:\n",
    "  - Quality metrics (OverallQual, etc.)\n",
    "  - Size/Area features (GrLivArea, TotalSF, etc.)\n",
    "  - Age-related features (HouseAge, YearsSinceRemodel, etc.)\n",
    "  - Garage and Basement features\n",
    "  - Location (Neighborhood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
